# LLM Chat API - Refactored Architecture

A FastAPI server with clean separation of concerns, making it easy for developers to understand and maintain.

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ services/           # Business logic layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rag_service.py  # RAG operations (PDF processing, embeddings, search)
â”‚   â””â”€â”€ chat_service.py # Chat operations (LLM responses)
â”œâ”€â”€ models/             # Data validation layer
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ requests.py     # API request models
â”‚   â””â”€â”€ responses.py    # API response models
â”œâ”€â”€ server.py           # Original monolithic server
â”œâ”€â”€ server_refactored.py # New modular server
â”œâ”€â”€ requirements.txt    # Dependencies
â””â”€â”€ temp_uploads/      # Temporary file storage
```

## ğŸ—ï¸ Architecture Overview

### **Service Layer** (`services/`)
- **RAGService**: Handles PDF processing, text chunking, embedding generation, and semantic search
- **ChatService**: Handles LLM interactions for both general chat and RAG responses

### **Model Layer** (`models/`)
- **Request Models**: Validate incoming API requests
- **Response Models**: Structure API responses

### **API Layer** (`server_refactored.py`)
- Clean endpoints that delegate to services
- Proper error handling and logging
- Dependency injection for services

## ğŸ”„ How It Works

### **Document Processing Flow:**
1. **Upload PDF** â†’ `RAGService.process_pdf()`
2. **LlamaParse** â†’ Extracts text from PDF
3. **Chunking** â†’ Splits text into manageable pieces
4. **OpenAI Embeddings** â†’ Generates vector embeddings for each chunk
5. **Storage** â†’ Chunks and embeddings stored in memory

### **Question Answering Flow:**
1. **User Question** â†’ `RAGService.get_relevant_chunks()`
2. **Semantic Search** â†’ Finds most similar document chunks
3. **Context Building** â†’ Combines relevant chunks
4. **LLM Response** â†’ `ChatService.generate_rag_response()`
5. **Answer** â†’ Returns response with context type indicator

## ğŸš€ Benefits of Refactoring

### **For Developers:**
- âœ… **Clear separation** - Business logic separate from API endpoints
- âœ… **Easy to understand** - Each file has a single responsibility
- âœ… **Easy to test** - Services can be tested independently
- âœ… **Easy to extend** - Add new services without touching API layer
- âœ… **Type safety** - Pydantic models ensure data validation

### **For Maintenance:**
- âœ… **Modular design** - Change one component without affecting others
- âœ… **Clear documentation** - Each service and model is well-documented
- âœ… **Error handling** - Centralized error handling in services
- âœ… **Logging** - Comprehensive logging for debugging

## ğŸ”§ Usage

### **Start the server:**
```bash
python server_refactored.py
```

### **API Endpoints:**
- `POST /query` - General chat
- `POST /rag/upload-pdf` - Upload PDF for processing
- `GET /rag/status/{job_id}` - Check processing status
- `POST /rag/ask` - Ask questions about uploaded documents
- `GET /rag/documents` - List processed documents

## ğŸ“ Key Clarifications

### **LlamaParse vs Embeddings:**
- **LlamaParse**: Only extracts text from PDFs (no embeddings)
- **OpenAI Embeddings**: Generated separately for semantic search
- **Our Architecture**: Combines both for complete RAG pipeline

### **Service Responsibilities:**
- **RAGService**: Document processing, embeddings, search
- **ChatService**: LLM interactions, response generation
- **Models**: Data validation and structure

This refactored architecture makes the codebase much more maintainable and easier for other developers to understand and extend! 